{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f289f6059cdd0ec",
   "metadata": {},
   "source": [
    "# Classifier Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e82f85ef849e31",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0172245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "parent_folder_path = os.getenv('PARENT_FOLDER', '.')\n",
    "sys.path.append(parent_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3ef6710a8c056c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T03:17:25.247641Z",
     "start_time": "2024-12-19T03:17:19.097335Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import gc\n",
    "from joblib import Parallel, delayed\n",
    "from collections import OrderedDict\n",
    "import platform\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as functional\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.resnet import resnet18\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import clear_output\n",
    "from tqdm.auto import tqdm\n",
    "# import torch_directml\n",
    "\n",
    "\n",
    "from libraries.segmentation.k_means import kmeans, KmeansFlags, KmeansTermCrit, KmeansTermOpt\n",
    "from libraries.improving.filtering import conv2d\n",
    "from dataset import TEST_DATASET, TRAIN_DATASET, get_elements_from_indexes, LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c1d32c3000961",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T03:17:25.299705Z",
     "start_time": "2024-12-19T03:17:25.270608Z"
    }
   },
   "outputs": [],
   "source": [
    "# MatPlotLib Configuration\n",
    "%matplotlib widget\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3690e3c51f74a92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T03:17:25.381970Z",
     "start_time": "2024-12-19T03:17:25.314008Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        # Use CUDA if available\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif platform.system() == \"Windows\":\n",
    "        # For Windows, use torch_directml if available\n",
    "        try:\n",
    "            import torch_directml\n",
    "            device = torch_directml.device()\n",
    "        except ImportError:\n",
    "            # Fallback to CPU if torch_directml is not installed\n",
    "            device = torch.device(\"cpu\")\n",
    "    elif platform.system() == \"Darwin\":\n",
    "        # For macOS, use MPS (Metal Performance Shaders) if available, otherwise CPU\n",
    "        if torch.backends.mps.is_available():\n",
    "            device = torch.device(\"mps\")\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "    else:\n",
    "        # Fallback for other platforms\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf8a176",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd8028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processed dataset files\n",
    "if not os.path.exists('pre_processed_dataset'):\n",
    "    os.mkdir('pre_processed_dataset')\n",
    "TRAIN_DATA_FILE = 'pre_processed_dataset/train.npy'\n",
    "TRAIN_LABELS_FILE = 'pre_processed_dataset/train_labels.npy'\n",
    "TEST_DATA_FILE = 'pre_processed_dataset/test.npy'\n",
    "TEST_LABELS_FILE = 'pre_processed_dataset/test_labels.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf3ad9112a85f68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T03:17:25.815171Z",
     "start_time": "2024-12-19T03:17:25.805927Z"
    }
   },
   "outputs": [],
   "source": [
    "# Functions\n",
    "# Plot single-channel images with a fixed configuration\n",
    "def draw_grayscale_image(image, ax):\n",
    "    ax.imshow(image, cmap='gray', vmin=0, vmax=255)\n",
    "    ax.axis('off')\n",
    "    \n",
    "# Clear output and then execute decorator\n",
    "def clear_and_execute(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        clear_output()\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "# Image pre-processing\n",
    "# Filter definition\n",
    "epsilon = 0.1\n",
    "sigma = 3\n",
    "gaussianDim = int(np.ceil(np.sqrt(-2 * sigma ** 2 * np.log(epsilon * sigma * np.sqrt(2 * np.pi)))))\n",
    "gaussianKernel1D = cv2.getGaussianKernel(gaussianDim, sigma)\n",
    "gaussianKernel = np.outer(gaussianKernel1D, gaussianKernel1D)\n",
    "@clear_and_execute\n",
    "def process_element(element):\n",
    "    image = element[0]\n",
    "    label = element[1]\n",
    "    filtered_image = conv2d(image, gaussianKernel)\n",
    "    compactness, labels, centers = kmeans(\n",
    "        filtered_image.flatten(), 3, \n",
    "        criteria=KmeansTermCrit(KmeansTermOpt.BOTH, 20, 0.5),\n",
    "        flags=KmeansFlags.KMEANS_PP_CENTERS, attempts=5\n",
    "    )\n",
    "    centers = centers.astype(np.uint8)\n",
    "    segmented_kmeans = centers[labels].reshape(image.shape)\n",
    "    sorted_centers = sorted(centers)\n",
    "    white_matter_idx = np.argmax(centers == sorted_centers[2])\n",
    "    grey_matter_idx = np.argmax(centers == sorted_centers[1])\n",
    "    segmented_white_matter = np.where(segmented_kmeans == centers[white_matter_idx], 1, 0).astype(np.uint8)\n",
    "    segmented_grey_matter = np.where(segmented_kmeans == centers[grey_matter_idx], 1, 0).astype(np.uint8)\n",
    "    return np.array((image, segmented_white_matter, segmented_grey_matter)), label\n",
    "\n",
    "# Parallel processing of images\n",
    "def parallel_processing(dataset_elements, img_shape):\n",
    "    dataset_length = len(dataset_elements)\n",
    "    data = np.zeros((dataset_length, 3, *img_shape), dtype=np.uint8)\n",
    "    labels = np.zeros((dataset_length,), dtype=np.uint8)\n",
    "    results = Parallel(n_jobs=8)(delayed(process_element)(element) for element in tqdm(dataset_elements))\n",
    "    for index in range(len(results)):\n",
    "        data[index] = results[index][0]\n",
    "        labels[index] = results[index][1]\n",
    "    return data, labels.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cad924978028d8",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17835d9fff2b72c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data Processing\n",
    "if not (os.path.exists(TRAIN_DATA_FILE) and os.path.exists(TRAIN_LABELS_FILE)):\n",
    "    train_dataset = load_dataset(**TRAIN_DATASET)\n",
    "    train_dataset_elements = get_elements_from_indexes(train_dataset, np.arange(len(train_dataset)))\n",
    "    img_shape = train_dataset_elements[0][0].shape\n",
    "    train_data, train_labels = parallel_processing(train_dataset_elements, img_shape)\n",
    "    print(\"Saving training data\")\n",
    "    np.save(TRAIN_DATA_FILE, train_data)\n",
    "    np.save(TRAIN_LABELS_FILE, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4236eff51805d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data Processing\n",
    "if not (os.path.exists(TEST_DATA_FILE) and os.path.exists(TEST_LABELS_FILE)):\n",
    "    test_dataset = load_dataset(**TEST_DATASET)\n",
    "    test_dataset_elements = get_elements_from_indexes(test_dataset, np.arange(len(test_dataset)))\n",
    "    img_shape = test_dataset_elements[0][0].shape\n",
    "    test_data, test_labels = parallel_processing(test_dataset_elements, img_shape)\n",
    "    print(\"Saving testing data\")\n",
    "    np.save(TEST_DATA_FILE, test_data)\n",
    "    np.save(TEST_LABELS_FILE, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec83307156a22644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the results\n",
    "train_data = np.load(TRAIN_DATA_FILE)\n",
    "train_labels = np.load(TRAIN_LABELS_FILE)\n",
    "random_index = np.random.randint(train_data.shape[0])\n",
    "sample = train_data[random_index]\n",
    "sample_image, sample_white_matter, sample_grey_matter = sample[0], sample[1], sample[2]\n",
    "sample_label = train_labels[random_index]\n",
    "if 'sample_fig' in globals():\n",
    "    plt.close('Sample image')\n",
    "sample_fig = plt.figure(figsize=(6, 2.3), num=\"Sample Image\")\n",
    "sample_axs = sample_fig.subplots(1, 3)\n",
    "draw_grayscale_image(sample_image, sample_axs[0])\n",
    "draw_grayscale_image(sample_white_matter * 255, sample_axs[1])\n",
    "draw_grayscale_image(sample_grey_matter * 255, sample_axs[2])\n",
    "sample_fig.suptitle(f\"Example Figure, label: {LABELS[sample_label]}\")\n",
    "sample_fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ec4f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b34380dd410c86",
   "metadata": {},
   "source": [
    "## Dataset Handlers & Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80a5c1ea8b097c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T03:17:32.162751Z",
     "start_time": "2024-12-19T03:17:32.149907Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset definition\n",
    "class DatasetHandler(Dataset):\n",
    "    def __init__(self, path_to_data: str, path_to_labels: str):\n",
    "        self.data = torch.tensor(np.load(path_to_data), dtype=torch.float)\n",
    "        self.data[:,0] /= 255 # Must be divided to be between 0 and 1\n",
    "        labels = np.load(path_to_labels)\n",
    "        self.labels = torch.zeros((len(labels), 4))\n",
    "        for index in range(len(labels)):\n",
    "            self.labels[index][labels[index]] = 1\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39518b60c0d7660d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T03:17:35.394834Z",
     "start_time": "2024-12-19T03:17:33.983180Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creation of dataloaders\n",
    "train_dataset_handler = DatasetHandler(TRAIN_DATA_FILE, TRAIN_LABELS_FILE)\n",
    "test_dataset_handler = DatasetHandler(TEST_DATA_FILE, TEST_LABELS_FILE)\n",
    "batch_size_train = 32\n",
    "batch_size_test = 128\n",
    "n_workers = 4\n",
    "train_dataloader = DataLoader(train_dataset_handler, batch_size=batch_size_train, shuffle=True,\n",
    "                              num_workers=0, pin_memory=False)\n",
    "test_dataloader = DataLoader(test_dataset_handler, batch_size=batch_size_test, shuffle=True,\n",
    "                             num_workers=0, pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366e48020157b563",
   "metadata": {},
   "source": [
    "## Module Initialization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b915479a2d7123",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T03:17:36.568553Z",
     "start_time": "2024-12-19T03:17:36.562937Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_weights(net, init='norm', gain=0.02, verbose: bool = True):\n",
    "    def init_func(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if hasattr(m, 'weight') and 'Conv' in classname:\n",
    "            if init == 'norm':\n",
    "                nn.init.normal_(m.weight.validation_data, mean=0.0, std=gain)\n",
    "            elif init == 'xavier':\n",
    "                nn.init.xavier_normal_(m.weight.validation_data, gain=gain)\n",
    "            elif init == 'kaiming':\n",
    "                nn.init.kaiming_normal_(m.weight.validation_data, a=0, mode='fan_in')\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(m.bias.validation_data, 0.0)\n",
    "        elif 'BatchNorm2d' in classname:\n",
    "            nn.init.normal_(m.weight.validation_data, 1., gain)\n",
    "            nn.init.constant_(m.bias.validation_data, 0.)\n",
    "    net.apply(init_func)\n",
    "    if verbose:\n",
    "        print(f\"Model initialized with {init} initialization.\")\n",
    "    return net\n",
    "\n",
    "\n",
    "def init_model(model, use_current_weights: bool = True, verbose: bool = True):\n",
    "    if use_current_weights:\n",
    "        if verbose:\n",
    "            print(\"Using current weights for the model.\")\n",
    "    else:\n",
    "        model = init_weights(model, verbose=verbose)\n",
    "        if verbose:\n",
    "            print(\"Initializing model weights.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838eb1b7c28a76aa",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeb4b24f04d71fd",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ce6a2fb77235c",
   "metadata": {},
   "source": [
    "#### Initialization with Pre-Trained Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aebb748824dc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T03:17:44.679496Z",
     "start_time": "2024-12-19T03:17:44.395758Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.models import efficientnet_b0\n",
    "\n",
    "efficientnet_model = efficientnet_b0(weights='IMAGENET1K_V1')\n",
    "\n",
    "efficientnet_skeleton = nn.Sequential(*list(efficientnet_model.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff64563f94c6adc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T03:17:46.119781Z",
     "start_time": "2024-12-19T03:17:46.046144Z"
    }
   },
   "outputs": [],
   "source": [
    "summary(efficientnet_skeleton, input_size=(3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c96b0fca7e7972",
   "metadata": {},
   "source": [
    "#### Custom CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c859a6cc17bbc0d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T03:17:48.168512Z",
     "start_time": "2024-12-19T03:17:48.155761Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_classification_layer_efficientnet(in_channels=1280, out_channels=1000):\n",
    "    return nn.Sequential(\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        nn.Flatten(),\n",
    "        nn.Dropout(0.2),\n",
    "        nn.Linear(in_features=in_channels, out_features=out_channels),\n",
    "    )\n",
    "\n",
    "class CustomEfficientNetB0(nn.Module):\n",
    "    def __init__(self, skeleton: nn.Module, use_current_weights: bool = True):\n",
    "        super().__init__()\n",
    "        self.skeleton = skeleton\n",
    "        self.classifier = init_model(get_classification_layer_efficientnet(1280, 4), use_current_weights=use_current_weights)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.classifier(self.skeleton(input))\n",
    "    \n",
    "    def set_requires_grad_skeleton(self, requires_grad: bool = True):\n",
    "        for param in self.skeleton.parameters():\n",
    "            param.requires_grad = requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f63405e2d615f75",
   "metadata": {},
   "source": [
    "#### Main Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08684ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainModel(nn.Module):\n",
    "    def __init__(self, skeleton: nn.Module, lr=1e-3, beta1=0.9, beta2=0.999, use_current_weights: bool = True, device=device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.net = CustomEfficientNetB0(skeleton, use_current_weights=use_current_weights).to(self.device)  # Changed this line\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.opt = optim.Adam(self.net.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "        self.input = None\n",
    "        self.target = None\n",
    "        self.prediction = None\n",
    "        self.ce_loss = None\n",
    "    def set_requires_grad(self, requires_grad=True):\n",
    "        for p in self.net.parameters():\n",
    "            p.requires_grad = requires_grad\n",
    "    def setup_input(self, data):\n",
    "        self.input = data[0].to(self.device)\n",
    "        self.target = data[1].to(self.device)\n",
    "    def forward(self):\n",
    "        self.prediction = self.net(self.input)\n",
    "    def backward(self):\n",
    "        self.ce_loss = self.criterion(self.prediction, self.target)\n",
    "        self.ce_loss.backward()\n",
    "    def optimize(self):\n",
    "        self.forward()\n",
    "        self.net.train()\n",
    "        self.opt.zero_grad()\n",
    "        self.backward()\n",
    "        self.opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bfd8235c2fd9f5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9867d82cab93740a",
   "metadata": {},
   "source": [
    "### Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30325731bb77f13e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T14:56:02.014630Z",
     "start_time": "2024-12-18T14:56:01.383097Z"
    }
   },
   "outputs": [],
   "source": [
    "from_checkpoint = False\n",
    "checkpoint_num = 1\n",
    "requires_grad_skeleton = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MainModel(efficientnet_skeleton, lr=5e-4)\n",
    "test_dataloader_iter = iter(test_dataloader)\n",
    "if not from_checkpoint:\n",
    "    last = 0\n",
    "else:\n",
    "    checkpoint = checkpoint_num\n",
    "    if checkpoint is None:\n",
    "        last = 0\n",
    "        classifier.load_state_dict(torch.load(os.path.join(parent_folder_path, \"model\", \"model.pth\")))\n",
    "    else:\n",
    "        last = checkpoint\n",
    "        classifier.load_state_dict(torch.load(os.path.join(parent_folder_path, \"model\", \"checkpoints\", f\"model_chckpt{checkpoint}.pth\")))\n",
    "if requires_grad_skeleton:\n",
    "    classifier.net.set_requires_grad_skeleton(True)\n",
    "else:\n",
    "    classifier.net.set_requires_grad_skeleton(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7231727abe5417",
   "metadata": {},
   "source": [
    "### Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16607dd7520eaab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T03:17:53.325642Z",
     "start_time": "2024-12-19T03:17:53.312694Z"
    }
   },
   "outputs": [],
   "source": [
    "class ModelCheckpoint:\n",
    "    def __init__(self, filepath='best_model.pth', monitor='val_f1', mode='max', save_best_only=True, verbose=True, current_value=None):\n",
    "        self.filepath = filepath\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.save_best_only = save_best_only\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        if mode == 'max':\n",
    "            self.best = float('-inf') if not current_value else current_value\n",
    "            self.monitor_op = lambda current, best: current > best\n",
    "        elif mode == 'min':\n",
    "            self.best = float('inf') if not current_value else current_value\n",
    "            self.monitor_op = lambda current, best: current < best\n",
    "        else:\n",
    "            raise ValueError(f\"Mode {mode} is unknown, please use 'max' or 'min'\")\n",
    "    \n",
    "    def __call__(self, current_value, model):\n",
    "        if self.monitor_op(current_value, self.best):\n",
    "            if self.verbose:\n",
    "                print(f'\\nEpoch: {self.monitor} improved from {self.best:.5f} to {current_value:.5f}, saving model to {self.filepath}')\n",
    "            self.best = current_value\n",
    "            torch.save(model.state_dict(), self.filepath)\n",
    "            return True\n",
    "        else:\n",
    "            if self.verbose and not self.save_best_only:\n",
    "                print(f'\\nEpoch: {self.monitor} did not improve from {self.best:.5f}')\n",
    "            return False\n",
    "\n",
    "def evaluate_model(model, test_dataloader, device):\n",
    "    \"\"\"Evaluate model on test set and return metrics\"\"\"\n",
    "    model.net.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            model.setup_input(data)\n",
    "            model.forward()\n",
    "            \n",
    "            predicted = np.argmax(functional.softmax(model.prediction.detach().cpu(), dim=1), axis=1)\n",
    "            labels = np.argmax(data[1].numpy(), axis=1)\n",
    "            \n",
    "            all_predictions.extend(predicted)\n",
    "            all_labels.extend(labels)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    \n",
    "    model.net.train()  # Set back to training mode\n",
    "    return {\n",
    "        'val_f1': f1,\n",
    "        'val_accuracy': accuracy,\n",
    "        'predictions': all_predictions,\n",
    "        'labels': all_labels\n",
    "    }\n",
    "\n",
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.count, self.avg, self.sum = [0.] * 3\n",
    "    def update(self, val, count=1):\n",
    "        self.count += count\n",
    "        self.sum += count * val\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def create_loss_meters():\n",
    "    loss = AverageMeter()\n",
    "    return {'ce_loss': loss}\n",
    "\n",
    "\n",
    "def update_losses(model, loss_meter_dict, count):\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        loss = getattr(model, loss_name)\n",
    "        loss_meter.update(loss.item(), count=count)\n",
    "\n",
    "\n",
    "def visualize(model, data, fig = None, ax = None):\n",
    "    labels = np.argmax(data[1], axis=1)\n",
    "    with torch.no_grad():\n",
    "        model.setup_input(data)\n",
    "        model.forward()\n",
    "    predicted = np.argmax(functional.softmax(model.prediction.detach().cpu(), dim=1), axis=1)\n",
    "    c_mat = confusion_matrix(labels, predicted, labels=np.arange(4))\n",
    "    if ax is not None:\n",
    "        ax.clear()\n",
    "    categories = list(map(lambda x: x[1], sorted(list(LABELS.items()), key=lambda x: x[0])))\n",
    "    sns.heatmap(c_mat/c_mat.sum(), \n",
    "                xticklabels=categories, yticklabels=categories,\n",
    "                cmap='Blues',\n",
    "                fmt='.2%',\n",
    "                ax=ax,\n",
    "                cbar=False)\n",
    "    if fig is not None:\n",
    "        fig.show()\n",
    "\n",
    "\n",
    "def log_results(loss_meter_dict):\n",
    "    log = \"\"\n",
    "    for loss_name, loss_meter in loss_meter_dict.items():\n",
    "        log += f\"{loss_name}: {loss_meter.avg:.5f} \"\n",
    "    return log\n",
    "\n",
    "def visualize_from_predictions(predictions, labels, fig=None, ax=None):\n",
    "    \"\"\"Visualize confusion matrix from predictions and labels\"\"\"\n",
    "    c_mat = confusion_matrix(labels, predictions, labels=np.arange(4))\n",
    "    if ax is not None:\n",
    "        ax.clear()\n",
    "    categories = list(map(lambda x: x[1], sorted(list(LABELS.items()), key=lambda x: x[0])))\n",
    "    sns.heatmap(c_mat/c_mat.sum(), \n",
    "                xticklabels=categories, yticklabels=categories,\n",
    "                cmap='Blues',\n",
    "                fmt='.2%',\n",
    "                ax=ax,\n",
    "                cbar=False)\n",
    "    if fig is not None:\n",
    "        fig.canvas.draw_idle()\n",
    "\n",
    "def load_best_model(model: MainModel, filepath='best_model.pth'):\n",
    "    \"\"\"Load the best model weights\"\"\"\n",
    "    if os.path.exists(filepath):\n",
    "        model.load_state_dict(torch.load(filepath))\n",
    "        print(f\"Loaded best model weights from {filepath}\")\n",
    "    else:\n",
    "        print(f\"No saved model found at {filepath}\")\n",
    "    return model\n",
    "\n",
    "def train_model_with_callbacks(model: MainModel, train_dl: DataLoader, test_dl: DataLoader,\n",
    "                               epochs: int = 100, display_every: int = 1, \n",
    "                               check_point_start: int = 0, checkpoint_callback=None,\n",
    "                               fig=None, ax=None):\n",
    "    \"\"\"Enhanced training function with callback support\"\"\"\n",
    "    check_point = check_point_start\n",
    "    best_metrics = {'val_f1': 0, 'val_accuracy': 0}\n",
    "\n",
    "    # Initial performance evaluation\n",
    "    val_metrics = evaluate_model(model, test_dl, model.device)\n",
    "    \n",
    "    # Initialize checkpoint callback if not provided\n",
    "    if checkpoint_callback is None:\n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            filepath='best_model.pth', \n",
    "            monitor='val_f1', \n",
    "            mode='max', \n",
    "            verbose=True,\n",
    "            current_value=val_metrics['val_f1']\n",
    "        )\n",
    "    \n",
    "    epoch_tqdm = tqdm(range(epochs), \"Epochs\", position=0, leave=True)\n",
    "    \n",
    "    for epoch in epoch_tqdm:\n",
    "        # Training phase\n",
    "        model.net.train()\n",
    "        loss_meter_dict = create_loss_meters()\n",
    "        batch_tqdm = tqdm(train_dl, \"Batches\", position=1, leave=False)\n",
    "        \n",
    "        for data in batch_tqdm:\n",
    "            model.setup_input(data)\n",
    "            model.optimize()\n",
    "            update_losses(model, loss_meter_dict, count=len(data[0]))\n",
    "        \n",
    "        batch_tqdm.close()\n",
    "        \n",
    "        # Validation phase\n",
    "        val_metrics = evaluate_model(model, test_dl, model.device)\n",
    "        \n",
    "        # Update best metrics\n",
    "        if val_metrics['val_f1'] > best_metrics['val_f1']:\n",
    "            best_metrics = val_metrics.copy()\n",
    "        \n",
    "        # Checkpoint callback\n",
    "        is_best = checkpoint_callback(val_metrics['val_f1'], model)\n",
    "        \n",
    "        # Logging\n",
    "        train_loss = log_results(loss_meter_dict)\n",
    "        epoch_desc = f\"{train_loss}val_f1: {val_metrics['val_f1']:.5f} val_acc: {val_metrics['val_accuracy']:.5f}\"\n",
    "        if is_best:\n",
    "            epoch_desc += \" [BEST]\"\n",
    "        epoch_tqdm.set_description(epoch_desc)\n",
    "        \n",
    "        # Visualization\n",
    "        if not (epoch + 1) % display_every and fig is not None and ax is not None:\n",
    "            visualize_from_predictions(val_metrics['predictions'], val_metrics['labels'], fig, ax)\n",
    "    \n",
    "    return check_point, best_metrics, checkpoint_callback.best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73c6cc6cb7fcf5f",
   "metadata": {},
   "source": [
    "### Validation Set Performance Supervision During Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ca85f680832a0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T14:56:31.861381Z",
     "start_time": "2024-12-18T14:56:31.827794Z"
    }
   },
   "outputs": [],
   "source": [
    "## Training Supervision\n",
    "if 'train_figure' in globals():\n",
    "    plt.close('Test Validation')\n",
    "train_figure = plt.figure(num='Test Validation', figsize=(8,8))\n",
    "train_ax = train_figure.subplots(1,1)\n",
    "train_figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9105b9e5bac054",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99006efa4cfe06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with callbacks\n",
    "N_epochs = 100\n",
    "Show_Every_N_epochs = 1\n",
    "\n",
    "# Create checkpoint callback\n",
    "best_model_callback = ModelCheckpoint(\n",
    "    filepath='best_model.pth',\n",
    "    monitor='val_f1',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Train with callbacks\n",
    "last, best_metrics, best_f1_score = train_model_with_callbacks(\n",
    "    classifier, \n",
    "    train_dataloader, \n",
    "    test_dataloader,  # Use full dataloader instead of iterator\n",
    "    N_epochs, \n",
    "    Show_Every_N_epochs,\n",
    "    last, \n",
    "    best_model_callback,\n",
    "    train_figure, \n",
    "    train_ax\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining completed!\")\n",
    "print(f\"Best validation F1 score: {best_f1_score:.5f}\")\n",
    "print(f\"Best validation accuracy: {best_metrics['val_accuracy']:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feb3fc60659787c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13be8f4ca6939bbd",
   "metadata": {},
   "source": [
    "### Checkpoint Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d34ea948ad5818d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T14:57:11.882335Z",
     "start_time": "2024-12-18T14:56:40.867414Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the best model automatically\n",
    "best_classifier = MainModel(efficientnet_skeleton)\n",
    "best_classifier = load_best_model(best_classifier, 'best_model.pth')\n",
    "\n",
    "# Get final predictions\n",
    "validation_data = test_dataset_handler[:]\n",
    "with torch.no_grad():\n",
    "    best_classifier.setup_input(validation_data)\n",
    "    best_classifier.forward()\n",
    "predicted = np.argmax(functional.softmax(best_classifier.prediction.detach().cpu(), dim=1), axis=1)\n",
    "labels = np.argmax(validation_data[1], axis=1)\n",
    "\n",
    "print(f\"Final evaluation on best model:\")\n",
    "print(f\"F1 Score: {f1_score(labels, predicted, average='weighted'):.5f}\")\n",
    "print(f\"Accuracy: {accuracy_score(labels, predicted):.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ec97c8f97120c1",
   "metadata": {},
   "source": [
    "### Best Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af936d6ae29f3abc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T03:31:58.822906Z",
     "start_time": "2024-12-19T03:31:58.807279Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to plot the confusion matrix\n",
    "def plot_confusion_matrix(ground_truth, predictions, fig = None, ax = None, mode: str = \"recall\"):\n",
    "    c_mat = confusion_matrix(ground_truth, predictions, labels=np.arange(4)).astype(np.float64)\n",
    "    if mode == \"recall\":\n",
    "        row_sums = c_mat.sum(axis=1)\n",
    "        for index in range(c_mat.shape[0]):\n",
    "            c_mat[index] /= row_sums[index]\n",
    "    elif mode == \"precision\":\n",
    "        column_sums = c_mat.sum(axis=0)\n",
    "        for index in range(c_mat.shape[1]):\n",
    "            c_mat[:, index] /= column_sums[index]\n",
    "    else:\n",
    "        raise ValueError(\"Mode should be either 'recall' or 'precision'\")\n",
    "    if ax is not None:\n",
    "        ax.clear()\n",
    "    categories = list(map(lambda x: x[1], sorted(list(LABELS.items()), key=lambda x: x[0])))\n",
    "    sns.heatmap(c_mat, \n",
    "                xticklabels=categories, yticklabels=categories,\n",
    "                cmap='Blues',\n",
    "                fmt='.2%',\n",
    "                ax=ax,\n",
    "                cbar=False,\n",
    "                annot=True)\n",
    "    if fig is not None:\n",
    "        fig.tight_layout()\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcb273149912b0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T03:33:38.694222Z",
     "start_time": "2024-12-19T03:33:38.555261Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show Confusion Matrix\n",
    "if 'fig_results' in globals():\n",
    "    plt.close('Results')\n",
    "fig_results = plt.figure(num='Results', figsize=(7,7))\n",
    "ax_results = fig_results.subplots(1,1)\n",
    "fig_results.suptitle('Recall', fontsize=14, fontweight='bold')\n",
    "fig_results.supxlabel('Model Predictions')\n",
    "fig_results.supylabel('Ground Truth')\n",
    "plot_confusion_matrix(labels, predicted, fig_results, ax_results, \"recall\")\n",
    "fig_results.savefig(\"confusion_matrix_recall.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626c637346d44f89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T03:19:24.672887Z",
     "start_time": "2024-12-19T03:19:24.648183Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show Report\n",
    "target_names = list(map(lambda x: x[1], sorted(list(LABELS.items()), key=lambda x: x[0])))\n",
    "report = classification_report(labels, predicted, target_names=target_names)\n",
    "score = f1_score(labels, predicted, average='weighted')\n",
    "accuracy = accuracy_score(labels, predicted)\n",
    "recall = recall_score(labels, predicted, average='weighted')\n",
    "precision = precision_score(labels, predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2797f9a17f7e9a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-19T03:19:26.406066Z",
     "start_time": "2024-12-19T03:19:26.401340Z"
    }
   },
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a691279a6576cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Model results:\\nAccuracy: {accuracy:.2f}\\nRecall: {recall:.2f}\\nPrecision: {precision:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804c295a0656f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint as the deployment model\n",
    "torch.save(best_classifier.state_dict(), os.path.join(rf'model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6237b35e03ef11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell when the system's memory is running low\n",
    "gc.collect()\n",
    "clear_output()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pib-final-assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
